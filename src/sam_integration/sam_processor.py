"""
SAM 3D Objects integration for generating 3D point clouds from 2D images
"""
import numpy as np
from PIL import Image
import torch
import os
from pathlib import Path
from typing import List, Tuple
import cv2


class SAMProcessor:
    """Handles SAM 3D Objects processing pipeline"""

    def __init__(self, checkpoint_path=None):
        """
        Initialize SAM processor

        Args:
            checkpoint_path: Path to SAM 3D Objects checkpoint
        """
        self.checkpoint_path = checkpoint_path or "checkpoints/sam-3d-objects"
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.sam_model = None
        self.inference = None

    def load_model(self):
        """Load SAM 3D Objects model"""
        try:
            # Import SAM 3D Objects modules
            # Note: This assumes sam-3d-objects is installed
            # Users need to follow: https://github.com/facebookresearch/sam-3d-objects
            from sam_3d_objects.inference import Inference

            config_path = os.path.join(self.checkpoint_path, "pipeline.yaml")

            if not os.path.exists(config_path):
                raise FileNotFoundError(
                    f"Config not found at {config_path}. "
                    "Please install SAM 3D Objects following: "
                    "https://github.com/facebookresearch/sam-3d-objects"
                )

            self.inference = Inference(config_path)
            print(f"SAM 3D Objects model loaded successfully on {self.device}")

        except ImportError:
            raise ImportError(
                "SAM 3D Objects not installed. Please install from: "
                "https://github.com/facebookresearch/sam-3d-objects"
            )

    def generate_mask(self, image: Image.Image, points: List[Tuple[int, int]]) -> np.ndarray:
        """
        Generate segmentation mask from selected points

        Args:
            image: Input PIL Image
            points: List of (x, y) coordinates selected by user

        Returns:
            Binary mask as numpy array
        """
        # Convert image to numpy array
        img_array = np.array(image)
        h, w = img_array.shape[:2]

        # Create initial mask using simple region growing or use SAM for segmentation
        # For now, we'll create a simple mask around the points
        # In production, you'd want to use SAM (Segment Anything Model) here
        mask = np.zeros((h, w), dtype=np.uint8)

        if len(points) == 1:
            # Single point - use grabcut or simple circle
            x, y = points[0]
            radius = min(h, w) // 4
            cv2.circle(mask, (x, y), radius, 255, -1)
        else:
            # Multiple points - create polygon or use as seeds
            points_array = np.array(points, dtype=np.int32)
            cv2.fillPoly(mask, [points_array], 255)

        # Optional: Use SAM for better segmentation
        # This would require SAM 2 to be installed
        # mask = self._use_sam_for_mask(img_array, points)

        return mask

    def _use_sam_for_mask(self, image: np.ndarray, points: List[Tuple[int, int]]) -> np.ndarray:
        """
        Use SAM (Segment Anything Model) to generate better masks from points

        Args:
            image: Input image as numpy array
            points: List of (x, y) coordinates

        Returns:
            Binary mask generated by SAM
        """
        try:
            # This is a placeholder for SAM integration
            # To implement this, you would:
            # 1. Install segment-anything: pip install segment-anything
            # 2. Download SAM checkpoint
            # 3. Use SAM predictor with points as prompts

            from segment_anything import sam_model_registry, SamPredictor

            # Load SAM model (this should be done once in __init__)
            sam_checkpoint = "checkpoints/sam_vit_h_4b8939.pth"
            model_type = "vit_h"

            sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
            sam.to(device=self.device)
            predictor = SamPredictor(sam)

            # Set image
            predictor.set_image(image)

            # Convert points to SAM format
            input_points = np.array(points)
            input_labels = np.ones(len(points))  # All foreground points

            # Predict mask
            masks, scores, logits = predictor.predict(
                point_coords=input_points,
                point_labels=input_labels,
                multimask_output=False,
            )

            return (masks[0] * 255).astype(np.uint8)

        except ImportError:
            print("Warning: SAM not installed, using simple mask generation")
            # Fallback to simple mask
            return self.generate_mask(Image.fromarray(image), points)

    def generate_point_cloud(
        self,
        image: Image.Image,
        mask: np.ndarray,
        output_dir: str = "data/output",
        seed: int = 42
    ) -> str:
        """
        Generate 3D point cloud using SAM 3D Objects

        Args:
            image: Input PIL Image
            mask: Binary segmentation mask
            output_dir: Output directory for .ply file
            seed: Random seed for reproducibility

        Returns:
            Path to generated .ply file
        """
        # Load model if not already loaded
        if self.inference is None:
            self.load_model()

        # Create output directory
        os.makedirs(output_dir, exist_ok=True)

        # Convert inputs to required format
        image_array = np.array(image)

        # Run SAM 3D Objects inference
        output = self.inference(image_array, mask, seed=seed)

        # Export gaussian splat to PLY
        ply_filename = f"output_{seed}.ply"
        ply_path = os.path.join(output_dir, ply_filename)

        # Save the gaussian splat
        output["gs"].save_ply(ply_path)

        print(f"Point cloud saved to: {ply_path}")
        return ply_path

    def load_image(self, image_path: str) -> Image.Image:
        """Load image from file path"""
        return Image.open(image_path).convert("RGB")

    def load_mask(self, mask_path: str) -> np.ndarray:
        """Load mask from file path"""
        mask = Image.open(mask_path).convert("L")
        return np.array(mask)
